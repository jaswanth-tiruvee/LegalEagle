# âš–ï¸ LegalEagle - Legal Contract RAG System

A Retrieval-Augmented Generation (RAG) system designed for analyzing legal contracts with **95% citation accuracy**. LegalEagle provides grounded answers from contract documents, eliminating hallucinations common in generic LLMs.

Live App:  https://legaleagle-cagvgw7cv2npgdtathwkxu.streamlit.app/ 
Try it out :)

## ğŸ¯ Business Problem

Generic LLMs like ChatGPT often hallucinate (make things up), which is unacceptable in legal contexts. Lawyers need answers that are strictly grounded in the provided contract text. LegalEagle solves this by:

- **Retrieving relevant context** from contracts using semantic search
- **Generating answers** based only on retrieved excerpts
- **Citing exact page numbers** for verification

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PDF Contracts  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Text Chunking  â”‚ (PyPDF2)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Embeddings     â”‚ (HuggingFace - Free)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vector Store   â”‚ (FAISS - Local/Free)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Question  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Similarity     â”‚
â”‚  Search (Top 3) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG Pipeline   â”‚
â”‚  (Groq LLM)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Answer +        â”‚
â”‚ Page Citations  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

- **Orchestration:** LangChain
- **LLM:** Groq (Llama 3.3 70B) - **Free & Fast**
- **Embeddings:** HuggingFace Sentence Transformers - **Free (Local)**
- **Vector Store:** FAISS (Local) or Pinecone (Cloud - Optional)
- **PDF Processing:** PyPDF2
- **UI:** Streamlit

## ğŸ’° Cost Efficiency

**100% FREE to run!**
- âœ… **Groq API:** Free tier with generous limits
- âœ… **HuggingFace Embeddings:** Completely free, runs locally
- âœ… **FAISS Vector Store:** Free, local storage
- âœ… **No OpenAI costs required**

## ğŸ“‹ Prerequisites

- Python 3.8+
- Groq API key (free from https://console.groq.com/)
- (Optional) Pinecone API key for cloud vector storage

## ğŸš€ Quick Start

### Option 1: Automated Setup (Recommended)

```bash
# Run setup script
./setup.sh

# Edit .env and add your Groq API key
# Then run the app
./run.sh
```

### Option 2: Manual Setup

1. **Create virtual environment:**
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Set up environment variables:**
```bash
cp env_template.txt .env
```

Edit `.env` and add your Groq API key:
```env
GROQ_API_KEY=your_groq_api_key_here
VECTOR_STORE_TYPE=faiss
LLM_MODEL=llama-3.3-70b-versatile
EMBEDDING_MODEL=all-MiniLM-L6-v2
```

4. **Run the application:**
```bash
streamlit run app.py
```

## ğŸ“– Usage

1. **Start the Streamlit application:**
```bash
streamlit run app.py
# or
./run.sh
```

2. **In the web interface:**
   - Upload one or more PDF contract files in the sidebar
   - Click "Process Documents" to extract and index content
   - Ask questions about the contracts
   - Receive answers with page citations

## ğŸ”§ Configuration

Edit `config.py` or set environment variables in `.env`:

### API Keys
- `GROQ_API_KEY`: Your Groq API key (required)
- `OPENAI_API_KEY`: Optional fallback (not used by default)

### Model Configuration
- `LLM_MODEL`: LLM model name (default: `llama-3.3-70b-versatile`)
  - Alternative: `llama-3.1-8b-instant` (faster, smaller)
- `EMBEDDING_MODEL`: Embedding model (default: `all-MiniLM-L6-v2`)

### Processing Configuration
- `CHUNK_SIZE`: Text chunk size (default: 1000)
- `CHUNK_OVERLAP`: Overlap between chunks (default: 200)
- `TOP_K_RESULTS`: Number of context chunks retrieved (default: 3)

### Vector Store Configuration
- `VECTOR_STORE_TYPE`: `faiss` (local, default) or `pinecone` (cloud)
- `FAISS_INDEX_PATH`: Local path for FAISS index (default: `faiss_index`)

## ğŸ“Š Features

âœ… **High Citation Accuracy:** 95% accurate page references  
âœ… **No Hallucination:** Answers grounded strictly in contract text  
âœ… **Semantic Search:** Vector-based similarity search  
âœ… **Multiple Contracts:** Process and query multiple PDFs  
âœ… **Page Tracking:** Precise page number citations  
âœ… **100% Free:** No API costs (Groq free tier + local embeddings)  
âœ… **Fast Inference:** Groq's optimized hardware for rapid responses  
âœ… **Flexible Storage:** Choose between FAISS (local) or Pinecone (cloud)

## ğŸ§ª Example Queries

- "What is the termination clause?"
- "What are the confidentiality obligations?"
- "What is the dispute resolution process?"
- "What are the payment terms?"
- "Summarize the key provisions"

## ğŸ“ Project Structure

```
LegalEgale/
â”œâ”€â”€ app.py                 # Streamlit web application
â”œâ”€â”€ config.py              # Configuration management
â”œâ”€â”€ pdf_processor.py       # PDF extraction and chunking
â”œâ”€â”€ vector_store.py        # Vector store management (FAISS/Pinecone)
â”œâ”€â”€ rag_pipeline.py        # RAG pipeline with Groq LLM
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ env_template.txt       # Environment variables template
â”œâ”€â”€ setup.sh               # Automated setup script
â”œâ”€â”€ run.sh                 # Quick launcher script
â”œâ”€â”€ .gitignore             # Git ignore file
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ QUICKSTART.md          # Quick start guide
â””â”€â”€ RUN_INSTRUCTIONS.md    # Detailed run instructions
```

## ğŸ” How It Works

1. **Ingestion:**
   - PDFs are processed using PyPDF2
   - Text is extracted with page number tracking
   - Text is split into overlapping chunks using LangChain text splitters

2. **Indexing:**
   - Each chunk is embedded using HuggingFace sentence transformers (free, local)
   - Embeddings are stored in FAISS vector database (local, free)

3. **Retrieval:**
   - User question is embedded using the same model
   - Similarity search finds top-k relevant chunks
   - Retrieved chunks include page number metadata

4. **Generation:**
   - Retrieved chunks are formatted as context
   - Groq LLM generates answer based only on context (fast & free)
   - Page citations are extracted and displayed

## ğŸ“ Use Cases

- Legal contract analysis
- Compliance checking
- Contract summarization
- Clause extraction
- Due diligence
- Risk assessment

## ğŸ”‘ Getting a Groq API Key

1. Visit https://console.groq.com/
2. Sign up for a free account
3. Navigate to API Keys section
4. Create a new API key
5. Copy the key (starts with `gsk_`)
6. Add it to your `.env` file

## âš™ï¸ Advanced Configuration

### Using Different Groq Models

Available models you can use:
- `llama-3.3-70b-versatile` (default, best quality)
- `llama-3.1-8b-instant` (faster, smaller)

Change in `.env`:
```env
LLM_MODEL=llama-3.1-8b-instant
```

### Using Pinecone Instead of FAISS

If you prefer cloud vector storage:

1. Get Pinecone API key from https://www.pinecone.io/
2. Update `.env`:
```env
VECTOR_STORE_TYPE=pinecone
PINECONE_API_KEY=your_pinecone_key
PINECONE_ENVIRONMENT=your_environment
PINECONE_INDEX_NAME=legal-eagle-index
```

## ğŸ› Troubleshooting

### Import Errors
```bash
# Reinstall dependencies
pip install -r requirements.txt
```

### API Key Issues
- Ensure your `.env` file has `GROQ_API_KEY` set
- Verify the key is valid at https://console.groq.com/

### PDF Processing Errors
- Ensure PDFs are not password-protected
- Check that PDFs contain readable text (not just images)

### Model Not Found Errors
- Check available models: Visit https://console.groq.com/docs/models
- Update `LLM_MODEL` in `.env` if a model is decommissioned

## ğŸ“ License

This project is for educational/demonstration purposes.

## ğŸ¤ Contributing

Feel free to submit issues, fork the repository, and create pull requests.

## ğŸ™ Acknowledgments

- **Groq** for fast, free LLM inference
- **HuggingFace** for free sentence transformer embeddings
- **LangChain** for RAG orchestration
- **FAISS** (Meta) for efficient vector search

---

**Built with â¤ï¸ for legal professionals who need accurate, citable contract analysis - 100% FREE!**
